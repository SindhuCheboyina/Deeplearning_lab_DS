{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"cifar10-CNN(Batch Norm2).ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOvipWWe00vNLPR4BJ6v2RJ"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"N6SrY5PnaJDf","colab_type":"code","colab":{}},"source":["import sys\n","from matplotlib import pyplot\n","from keras.datasets import cifar10\n","from keras.utils import to_categorical\n","from keras.models import Sequential\n","from keras.layers import Conv2D\n","from keras.layers import MaxPooling2D\n","from keras.layers import Dense\n","from keras.layers import Flatten\n","from keras.optimizers import SGD\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.layers import Dropout\n","from keras.layers import BatchNormalization"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"03nkaKq32rpR","colab_type":"code","colab":{}},"source":["# load train and test dataset\n","def load_dataset():\n","\t# load dataset\n","\t(trainX, trainY), (testX, testY) = cifar10.load_data()\n","\t# one hot encode target values\n","\ttrainY = to_categorical(trainY)\n","\ttestY = to_categorical(testY)\n","\treturn trainX, trainY, testX, testY"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ew1w1ULW2wh6","colab_type":"code","colab":{}},"source":["# scale pixels\n","def prep_pixels(train, test):\n","\t# convert from integers to floats\n","\ttrain_norm = train.astype('float32')\n","\ttest_norm = test.astype('float32')\n","\t# normalize to range 0-1\n","\ttrain_norm = train_norm / 255.0\n","\ttest_norm = test_norm / 255.0\n","\t# return normalized images\n","\treturn train_norm, test_norm\n"," "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gwi2e4ZV24Ua","colab_type":"code","colab":{}},"source":["# define cnn model\n","def define_model():\n","  model = Sequential()\n","  model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n","  model.add(BatchNormalization())\n","  model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n","  model.add(BatchNormalization())\n","  model.add(MaxPooling2D((2, 2)))\n","  model.add(Dropout(0.2))\n","  '''model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n","  model.add(BatchNormalization())\n","  model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n","  model.add(BatchNormalization())\n","  model.add(MaxPooling2D((2, 2)))\n","  model.add(Dropout(0.3))\n","  model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n","  model.add(BatchNormalization())\n","  model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n","  model.add(BatchNormalization())\n","  model.add(MaxPooling2D((2, 2)))\n","  model.add(Dropout(0.4))'''\n","  model.add(Flatten())\n","  model.add(Dense(128, activation='relu', kernel_initializer='he_uniform',))\n","  model.add(BatchNormalization())\n","  model.add(Dropout(0.5))\n","  model.add(Dense(10, activation='softmax'))\n","  # compile model\n","  opt = SGD(lr=0.001, momentum=0.9)\n","  model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oliI-hGd3NDo","colab_type":"code","colab":{}},"source":["# plot diagnostic learning curves\n","def summarize_diagnostics(history):\n","\t# plot loss\n","\tpyplot.subplot(211)\n","\tpyplot.title('Cross Entropy Loss')\n","\tpyplot.plot(history.history['loss'], color='blue', label='train')\n","\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n","\t# plot accuracy\n","\tpyplot.subplot(212)\n","\tpyplot.title('Classification Accuracy')\n","\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n","\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n","\t# save plot to file\n","\tfilename = sys.argv[0].split('/')[-1]\n","\tpyplot.savefig(filename + '_plot.png')\n","\tpyplot.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A5sVXq2k9GGD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595256489645,"user_tz":-330,"elapsed":5187186,"user":{"displayName":"Sindhu Cheboyina","photoUrl":"","userId":"16442690831391808379"}},"outputId":"8a411c02-7970-4d09-b4b9-1121a34ac328"},"source":["# run the test harness for evaluating a model\n","def run_test_harness():\n","\t# load dataset\n","\ttrainX, trainY, testX, testY = load_dataset()\n","\t# prepare pixel data\n","\ttrainX, testX = prep_pixels(trainX, testX)\n","\t# define model\n","\tmodel = define_model()\n","\t# create data generator\n","\tdatagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n","\t# prepare iterator\n","\tit_train = datagen.flow(trainX, trainY, batch_size=64)\n","\t# fit model\n","\tsteps = int(trainX.shape[0] / 64)\n","\thistory = model.fit_generator(it_train, steps_per_epoch=steps, epochs=25, validation_data=(testX, testY), verbose=0)\n","\t# evaluate model\n","\t_, acc = model.evaluate(testX, testY, verbose=0)\n","\tprint('> %.3f' % (acc * 100.0))\n","\t# learning curves\n","\tsummarize_diagnostics(history)\n"," \n","# entry point, run the test harness\n","run_test_harness()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["> 67.270\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"m8rL-qi9xGEh","colab_type":"text"},"source":["# New Section"]},{"cell_type":"markdown","metadata":{"id":"ocor8yaXxGsu","colab_type":"text"},"source":["# New Section"]}]}